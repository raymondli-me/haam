# HAAM Package Architecture Mind Map

## ğŸ—ï¸ Core Architecture Overview

```mermaid
graph TB
    subgraph "ğŸ“¦ HAAM Package Core"
        HAAM["ğŸ¯ HAAM<br/>(haam_init.py)<br/>Main Entry Point"]
        
        HAAM --> HAAMAnalysis["ğŸ“Š HAAMAnalysis<br/>(haam_package.py)<br/>Statistical Engine"]
        HAAM --> TopicAnalyzer["ğŸ” TopicAnalyzer<br/>(haam_topics.py)<br/>Topic Modeling"]
        HAAM --> HAAMVisualizer["ğŸ“ˆ HAAMVisualizer<br/>(haam_visualizations.py)<br/>Interactive Plots"]
        
        TopicAnalyzer --> PCWordCloud["â˜ï¸ PCWordCloudGenerator<br/>(haam_wordcloud.py)<br/>Word Clouds"]
    end
    
    subgraph "ğŸ“¥ Input Data"
        Y["Y (criterion)"]
        AI["AI Judgments"]
        HU["Human Judgments"]
        EMB["Embeddings/Texts"]
    end
    
    subgraph "ğŸ“¤ Outputs"
        Stats["Statistical Results<br/>(coefficients, p-values)"]
        Viz["Interactive Visualizations<br/>(HTML/Plotly)"]
        WC["Word Clouds<br/>(validity colored)"]
        JSON["Metrics JSON"]
    end
    
    Y --> HAAM
    AI --> HAAM
    HU --> HAAM
    EMB --> HAAM
    
    HAAMAnalysis --> Stats
    HAAMVisualizer --> Viz
    PCWordCloud --> WC
    HAAM --> JSON
```

## ğŸ”— Component Relationships

### 1. **HAAM Class (Main Orchestrator)**
```
haam/haam_init.py
â”‚
â”œâ”€â†’ Initializes with data (Y, AI, HU, embeddings/texts)
â”œâ”€â†’ Manages auto_run pipeline
â”œâ”€â†’ Coordinates all sub-components
â””â”€â†’ Provides unified API
```

### 2. **Statistical Analysis Flow**
```
HAAMAnalysis (haam_package.py)
â”‚
â”œâ”€â†’ PCA transformation (if embeddings provided)
â”œâ”€â†’ Sample-split post-lasso regression
â”œâ”€â†’ Debiased coefficient estimation
â””â”€â†’ Statistical significance testing
```

### 3. **Topic Modeling Pipeline**
```
TopicAnalyzer (haam_topics.py)
â”‚
â”œâ”€â†’ UMAP dimensionality reduction
â”œâ”€â†’ HDBSCAN clustering
â”œâ”€â†’ c-TF-IDF keyword extraction
â””â”€â†’ PC-topic association analysis
```

### 4. **Visualization Generation**
```
HAAMVisualizer (haam_visualizations.py)
â”‚
â”œâ”€â†’ Main HAAM diagram (3x3 grid)
â”œâ”€â†’ Coefficient comparison plots
â”œâ”€â†’ UMAP scatter plots
â”œâ”€â†’ PC arrow plots
â””â”€â†’ Interactive HTML output
```

### 5. **Word Cloud Creation**
```
PCWordCloudGenerator (haam_wordcloud.py)
â”‚
â”œâ”€â†’ High/Low pole word extraction
â”œâ”€â†’ Validity coloring logic
â”œâ”€â†’ Quartile-based coloring
â””â”€â†’ PNG/display output
```

## ğŸ“ File Structure & Usage

### âœ… **Core Files (Essential)**
- `haam/__init__.py` - Package exports
- `haam/haam_init.py` - Main HAAM class
- `haam/haam_package.py` - Statistical engine
- `haam/haam_topics.py` - Topic modeling
- `haam/haam_visualizations.py` - Visualizations
- `haam/haam_wordcloud.py` - Word clouds

### ğŸš€ **Main Usage Scripts**
- `run_haam_analysis.py` - Standard analysis runner
- `run_haam_analysis_v1.3.py` - Latest version with enhancements
- `examples/` - Example notebooks and scripts

### âš ï¸ **Potentially Removable (Clutter)**
```
generate_wordclouds_*.py (11 files)
â”œâ”€ generate_wordclouds_colab.py
â”œâ”€ generate_wordclouds_final.py
â”œâ”€ generate_wordclouds_quartile.py
â”œâ”€ generate_wordclouds_quartile_quartile.py
â”œâ”€ generate_wordclouds_quartile_quartile_final.py
â”œâ”€ generate_wordclouds_quartile_quartile_validity.py
â”œâ”€ generate_wordclouds_quartile_quartile_validity_final.py
â”œâ”€ generate_wordclouds_validity.py
â”œâ”€ generate_wordclouds_validity_final.py
â”œâ”€ generate_wordclouds_validity_final_aligned.py
â””â”€ generate_wordclouds_validity_final_aligned_v2.py â† LATEST/KEEP

test_*.py (6 files) - Development/debug scripts
backup files (*_backup.py)
older versions (v1.2, etc.)
```

## ğŸ”„ Data Flow Diagram

```
Input Data
    â†“
[HAAM Initialization]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. HAAMAnalysis                    â”‚
â”‚     â€¢ PCA (if needed)               â”‚
â”‚     â€¢ Sample-split post-lasso       â”‚
â”‚     â€¢ Statistical inference         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. TopicAnalyzer                   â”‚
â”‚     â€¢ UMAP reduction                â”‚
â”‚     â€¢ HDBSCAN clustering            â”‚
â”‚     â€¢ Keyword extraction            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. HAAMVisualizer                  â”‚
â”‚     â€¢ Generate interactive plots    â”‚
â”‚     â€¢ Create HTML output            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PCWordCloudGenerator            â”‚
â”‚     â€¢ Extract pole words            â”‚
â”‚     â€¢ Apply validity coloring       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Outputs (Stats, Plots, Word Clouds)
```

## ğŸ¨ Validity Coloring Logic

```
Validity Coloring (in word clouds):
â”‚
â”œâ”€ Consensus High (dark red): Y=H, HU=H, AI=H
â”œâ”€ Any High (light red): At least one = H
â”œâ”€ Consensus Low (dark blue): Y=L, HU=L, AI=L
â”œâ”€ Any Low (light blue): At least one = L
â”œâ”€ Opposing (gray): Mix of H and L
â””â”€ All Middle (light gray): All in middle quartile
```

## ğŸ”§ Specialized Variants

### HAAMwithBWS (haam_bws.py)
- For pre-computed interpretable features
- Bypasses PCA transformation
- Maintains statistical rigor
- Use case: Best-Worst Scaling features

## ğŸ“Š Your Main Script Connection

Your script (`generate_wordclouds_validity_final_aligned_v2.py`) uses:
1. **HAAM class** for main analysis
2. **TopicAnalyzer** (via haam.topic_analyzer) for topic data
3. **PCWordCloudGenerator** (via haam.create_pc_wordclouds) for word clouds
4. Custom helper functions for sparse data handling

## ğŸ¯ Recommendations

### Keep These:
- All files in `haam/` directory
- `run_haam_analysis_v1.3.py`
- `generate_wordclouds_validity_final_aligned_v2.py`
- `examples/` directory
- Configuration files (setup.py, pyproject.toml)

### Consider Removing:
- Older wordcloud generation scripts (keep only the latest)
- Test scripts (unless part of formal testing)
- Backup files
- Older version scripts

### Organize Into:
```
haam/
â”œâ”€â”€ haam/           # Core package (clean)
â”œâ”€â”€ scripts/        # Active usage scripts
â”œâ”€â”€ examples/       # Example notebooks
â”œâ”€â”€ tests/          # Formal test suite
â””â”€â”€ archive/        # Old/experimental scripts
```